# 金融风控训练营Task04建模与调参学习笔记
本学习笔记为阿里云天池龙珠计划Docker训练营的学习内容，学习链接为：
https://tianchi.aliyun.com/specials/activity/promotion/aicampfr?spm=5176.12901015.0.i12901015.419b525cZREgQM

## 一、学习知识点概要
* 常见模型
  * 逻辑回归模型
  * 树模型
  * 集成模型
* 模型相关原理
* 模型对比与性能评估

## 二、学习内容

### 常见模型及原理
* 逻辑回归模型
```
逻辑回归是应用非常广泛的一个分类机器学习算法，
它将数据拟合到一个logit函数(或者叫做logistic函数)中，从而能够完成对事件发生的概率进行预测。
它的核心思想是，如果线性回归的结果输出是一个连续值，而值的范围是无法限定的，那我们有没有办法把这个结果值映射为可以帮助我们判断的结果呢。
而如果输出结果是 (0,1) 的一个概率值，这个问题就很清楚了。
```
* 树模型
  * 决策树
  ```
  决策树(decision tree)是一种基本的分类与回归方法。
  我们可以把决策树看成一个if-then规则的集合，将决策树转换成if-then规则的过程是这样的：由决策树的根结点(root node)到叶结点(leaf node)的每一条路径构建一条规则；路径上内部结点的特征对应着规则的条件，而叶结点的类对应着规则的结论。决策树的路径或其对应的if-then规则集合具有一个重要的性质：互斥并且完备。这就是说，每一个实例都被一条路径或一条规则所覆盖，而且只被一条路径或一条规则所覆盖。这里所覆盖是指实例的特征与路径上的特征一致或实例满足规则的条件。
  ```
  
  ```
  使用决策树做预测需要以下过程：
  收集数据：可以使用任何方法。比如想构建一个相亲系统，我们可以从媒婆那里，或者通过参访相亲对象获取数据。根据他们考虑的因素和最终的选择结果，就可以得到一些供我们利用的数据了。
  准备数据：收集完的数据，我们要进行整理，将这些所有收集的信息按照一定规则整理出来，并排版，方便我们进行后续处理。
  分析数据：可以使用任何方法，决策树构造完成之后，我们可以检查决策树图形是否符合预期。
  训练算法：这个过程也就是构造决策树，同样也可以说是决策树学习，就是构造一个决策树的数据结构。
  测试算法：使用经验树计算错误率。当错误率达到了可接收范围，这个决策树就可以投放使用了。
  使用算法：此步骤可以使用适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义。
  ```
  
  ```
  #决策树构建的三个步骤
  特征选择、决策树的生成和决策树的修剪。
  ```
* 集成模型
  * 基于bagging思想的集成模型
    * cart回归树
    ```
    GBDT是一个集成模型，可以看做是很多个基模型的线性相加，其中的基模型就是CART回归树。
    CART树是一个决策树模型，与普通的ID3，C4.5相比，CART树的主要特征是，他是一颗二分树，每个节点特征取值为“是”和“不是”。举个例子，在ID3中如果天气是一个特征，那么基于此的节点特征取值为“晴天”、“阴天”、“雨天”，而CART树中就是“不是晴天”与“是晴天”。
    这样的决策树递归的划分每个特征，并且在输入空间的每个划分单元中确定唯一的输出。
    ```
  * 基于boosting思想的集成模型
    * XGBoost模型
    * LightGBM模型
    * CatBoost模型
### 模型对比与性能评估
#### 逻辑回归
* 优点
  * 训练速度较快，分类的时候，计算量仅仅只和特征的数目相关；
  * 适合二分类问题，不需要缩放输入特征；
* 缺点
  * 逻辑回归需要预先处理缺失值和异常值【可参考task3特征工程】；
  * 确率并不是很高，因为形式非常简单，很难去拟合数据的真实分布；

#### 决策树模型
* 优点
  * 数据不需要预处理，不需要归一化，不需要处理缺失数据
* 缺点
  * 决策树算法非常容易过拟合，导致泛化能力不强（可进行适当的剪枝）
  * 采用的是**贪心算法**，容易得到局部最优解

#### 模型评估
```
  对于模型来说，其在训练集上面的误差我们称之为训练误差或者经验误差，而在测试集上的误差称之为测试误差。
  对于我们来说，我们更关心的是模型对于新样本的学习能力，即我们希望通过对已有样本的学习，尽可能的将所有潜在样本的普遍规律学到手，而如果模型对训练样本学的太好，则有可能把训练样本自身所具有的一些特点当做所有潜在样本的普遍特点，这时候我们就会出现过拟合的问题。
  因此我们通常将已有的数据集划分为训练集和测试集两部分，其中训练集用来训练模型，而测试集则是用来评估模型对于新样本的判别能力。
  对于数据集的划分，我们通常要保证满足以下两个条件：
  训练集和测试集的分布要与样本真实分布一致，即训练集和测试集都要保证是从样本真实分布中独立同分布采样而得;
  训练集和测试集要互斥;
```
* 数据集划分的三种方法
  * 留出法
  * 交叉验证法
  * 自助法




## 三、学习问题与解答
* 逻辑回归相对于决策树有哪些优势，什么场景下逻辑回归比决策树效果更好？
```
当一种算法对于数据的假设与数据本身的情况一致，并且算法收敛性很好，就会有不错的效果。
```

## 四、学习思考与总结
在针对不同问题、不同数据选择模型时，除了考虑具体问题中的因素，还需要考虑数据本身的特点，以及不同模型针对数据做出的假设。本次task学习到的几个模型都比较难，三天时间太短所以也不大可能能够消化，所以我必须花更多的时间来学习和总结几种模型的原理及使用。

